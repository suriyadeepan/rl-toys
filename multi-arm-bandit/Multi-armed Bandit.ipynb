{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-armed Bandit\n",
    "\n",
    "[*reference*](https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-1-fd544fab149#.y721lsdjn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of bandits\n",
    "bandits = [0.2, 0, -0.2, -5]\n",
    "num_bandits = len(bandits)\n",
    "\n",
    "# generate a random number with mean 0\n",
    "def pull_bandit(bandit):\n",
    "    return 1 if np.random.randn(1) > bandit else -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo of how function works\n",
    "pull_bandit(random.choice(bandits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tf.slice](https://www.tensorflow.org/api_docs/python/array_ops/slicing_and_joining#slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let us build a neural network\n",
    "#  output : action\n",
    "#  input  : none\n",
    "#  training inputs : reward, action\n",
    "#  choose action : one with maximum weight (index)\n",
    "tf.reset_default_graph()\n",
    "w = tf.Variable(tf.ones([num_bandits])) # vector of len num_bandits\n",
    "action = tf.argmax(w,0) # tis a vector\n",
    "# training\n",
    "reward_ = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "action_ = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "best_weight = tf.slice(w,action_,[1])\n",
    "loss = -(tf.log(best_weight)*reward_)\n",
    "train_fn = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params\n",
    "num_epi = 1000\n",
    "rall = np.zeros(num_bandits)\n",
    "e = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward status : [-1.  0.  0.  0.]\n",
      "Reward status : [  1.  -4.  -2.  48.]\n",
      "Reward status : [  -2.   -6.    3.  104.]\n",
      "Reward status : [   1.   -8.   12.  160.]\n",
      "Reward status : [   3.  -14.   10.  210.]\n",
      "Reward status : [   0.  -12.   12.  271.]\n",
      "Reward status : [  -2.   -3.   22.  322.]\n",
      "Reward status : [  -6.   -7.   28.  380.]\n",
      "Reward status : [ -12.  -16.   35.  444.]\n",
      "Reward status : [  -6.  -13.   37.  495.]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epi):\n",
    "        # choose an action with prob > e\n",
    "        if np.random.randn(1) < e:\n",
    "            action_v = np.random.randint(num_bandits)\n",
    "        else:\n",
    "            action_v = sess.run(action)\n",
    "        # get reward for chosen action\n",
    "        reward_v = pull_bandit(bandits[action_v])\n",
    "        \n",
    "        # based on the reward and chosen action, update the network\n",
    "        sess.run(train_fn, feed_dict = {reward_ : [reward_v],\n",
    "                                        action_ : [action_v]\n",
    "                                       })\n",
    "        # keep track of rewards\n",
    "        rall[action_v] += reward_v\n",
    "        if i%100 == 0:\n",
    "            print('Reward status : {}'.format(rall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And the best bandit to pull is bandit #4\n"
     ]
    }
   ],
   "source": [
    "print('And the best bandit to pull is bandit #{}'.format(np.argmax(rall)+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
